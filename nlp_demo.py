#!/usr/bin/env python3
"""
NLP Engineering Demo for TikTok Hackathon
Showcases advanced NLP features and policy detection capabilities
"""

import pandas as pd
import numpy as np
import sys
sys.path.append('src')

from data_processing import TextPreprocessor, PolicyFeatureExtractor
from advanced_nlp_features import AdvancedNLPFeatureExtractor
from policy_detection_system import PolicyViolationDetector

class NLPShowcase:
    """Demonstrate NLP engineering capabilities for hackathon"""
    
    def __init__(self):
        print("üé≠ INITIALIZING NLP ENGINEERING SHOWCASE")
        print("=" * 60)
        
        # Initialize components
        self.basic_processor = TextPreprocessor()
        self.basic_policy = PolicyFeatureExtractor()
        self.advanced_extractor = AdvancedNLPFeatureExtractor()
        self.policy_detector = PolicyViolationDetector()
        
        print("‚úÖ All NLP components ready!")
    
    def demonstrate_feature_engineering(self):
        """Show advanced feature engineering capabilities"""
        
        print("\nüß† ADVANCED FEATURE ENGINEERING DEMONSTRATION")
        print("=" * 60)
        
        # Sample reviews that showcase different aspects
        demo_reviews = [
            "Excellent food and amazing service! The pasta was perfectly cooked and the staff was incredibly attentive.",
            "Visit our website www.restaurant-deals.com for incredible 50% off deals! Call now at 555-123-4567!",
            "I love my new iPhone 15 but this place is way too noisy for phone calls. WiFi is good though.",
            "Never actually been here but heard from my coworker that the service is absolutely terrible.",
            "The ambiance was perfect for our anniversary dinner. Highly recommend the salmon!"
        ]
        
        print(f"üìä Processing {len(demo_reviews)} diverse review examples...")
        
        for i, review in enumerate(demo_reviews):
            print(f"\nüîç REVIEW {i+1}: '{review[:60]}...'")
            
            # Basic preprocessing
            cleaned = self.basic_processor.clean_text(review)
            sentiment = self.basic_processor.get_sentiment_score(cleaned)
            
            # Advanced NLP features
            advanced_features = self.advanced_extractor.extract_all_advanced_features(review)
            
            # Show key insights
            print(f"   üìù Cleaned: '{cleaned[:50]}...'")
            print(f"   üòä Sentiment: {sentiment:.3f}")
            print(f"   üìè Reading level: {advanced_features.get('linguistic_flesch_kincaid_grade', 0):.1f}")
            print(f"   üéØ Total features extracted: {len(advanced_features)}")
            
            # Show some interesting features
            interesting = {
                'Readability': advanced_features.get('linguistic_flesch_reading_ease', 0),
                'Subjectivity': advanced_features.get('sentiment_textblob_subjectivity', 0),
                'Question count': advanced_features.get('linguistic_question_count', 0),
                'Exclamation count': advanced_features.get('linguistic_exclamation_count', 0),
                'Named entities': advanced_features.get('ner_total_entities', 0)
            }
            
            for feature, value in interesting.items():
                if isinstance(value, (int, float)):
                    print(f"     {feature}: {value:.2f}")
    
    def demonstrate_policy_detection(self):
        """Show sophisticated policy violation detection"""
        
        print("\nüõ°Ô∏è POLICY VIOLATION DETECTION DEMONSTRATION")
        print("=" * 60)
        
        # Test cases designed to trigger different violations
        test_cases = [
            {
                'text': "Fantastic food and great service! Will definitely return next week.",
                'expected': 'Quality Review',
                'violations': []
            },
            {
                'text': "Best pizza in town! Visit our website www.pizza-deals.com for 30% off your next order! Follow us @pizzacentral!",
                'expected': 'Advertisement',
                'violations': ['advertisement']
            },
            {
                'text': "I love my new MacBook Pro but this coffee shop is too loud for video calls. Good WiFi though.",
                'expected': 'Irrelevant Content',
                'violations': ['irrelevant']
            },
            {
                'text': "Never been to this restaurant but heard from friends that the food is terrible and overpriced.",
                'expected': 'Rant Without Visit',
                'violations': ['rant_no_visit']
            },
            {
                'text': "Check out our Instagram @foodiespot for daily specials! Call 555-FOOD-NOW for reservations!",
                'expected': 'Multiple Violations',
                'violations': ['advertisement']
            }
        ]
        
        print(f"üß™ Testing {len(test_cases)} policy violation scenarios...")
        
        for i, case in enumerate(test_cases):
            print(f"\nüîç TEST CASE {i+1}: {case['expected']}")
            print(f"   Text: '{case['text'][:80]}...'")
            
            # Apply rule-based detection
            ad_detector = self.policy_detector.rule_detectors['advertisement']
            irrelevant_detector = self.policy_detector.rule_detectors['irrelevant']
            rant_detector = self.policy_detector.rule_detectors['rant_no_visit']
            
            # Get detections and confidences
            ad_detected = ad_detector.detect(case['text'])
            ad_confidence = ad_detector.get_confidence(case['text'])
            ad_explanation = ad_detector.explain(case['text'])
            
            irrelevant_detected = irrelevant_detector.detect(case['text'])
            irrelevant_confidence = irrelevant_detector.get_confidence(case['text'])
            
            rant_detected = rant_detector.detect(case['text'])
            rant_confidence = rant_detector.get_confidence(case['text'])
            
            # Show results
            print(f"   üéØ DETECTIONS:")
            print(f"     Advertisement: {'‚úÖ' if ad_detected else '‚ùå'} (confidence: {ad_confidence:.2f})")
            if ad_explanation:
                print(f"       Reason: {ad_explanation}")
            
            print(f"     Irrelevant: {'‚úÖ' if irrelevant_detected else '‚ùå'} (confidence: {irrelevant_confidence:.2f})")
            print(f"     Rant w/o visit: {'‚úÖ' if rant_detected else '‚ùå'} (confidence: {rant_confidence:.2f})")
            
            # Overall quality assessment
            has_violations = any([ad_detected, irrelevant_detected, rant_detected])
            quality_score = 0 if has_violations else 1
            print(f"   üìä Overall Quality: {'‚úÖ GOOD' if quality_score else '‚ùå POOR'}")
    
    def demonstrate_real_data_processing(self):
        """Show processing of real Google Reviews data"""
        
        print("\nüìä REAL DATA PROCESSING DEMONSTRATION")
        print("=" * 60)
        
        try:
            # Load real data sample
            real_df = pd.read_csv('data/processed/validation_real_data.csv')
            sample_df = real_df.head(10)
            
            print(f"üìà Processing {len(sample_df)} real Google Maps reviews...")
            
            # Process with basic pipeline
            df_processed = self.basic_processor.preprocess_dataframe(sample_df, 'review_text')
            df_policy = self.basic_policy.extract_features_dataframe(df_processed, 'cleaned_text')
            
            # Apply policy detection
            df_violations = self.policy_detector.detect_violations_rules(df_policy)
            
            # Show summary statistics
            print(f"\nüìä PROCESSING RESULTS:")
            print(f"   Total features created: {len(df_violations.columns)}")
            print(f"   Advertisement violations: {df_violations['rule_advertisement'].sum()}")
            print(f"   Irrelevant content: {df_violations['rule_irrelevant'].sum()}")
            print(f"   Rants without visit: {df_violations['rule_rant_no_visit'].sum()}")
            print(f"   Quality reviews: {df_violations['rule_overall_quality'].sum()}")
            
            # Show some examples
            print(f"\nüîç SAMPLE RESULTS:")
            for idx in range(min(3, len(df_violations))):
                row = df_violations.iloc[idx]
                text = row['review_text'][:60]
                rating = row.get('rating', 'N/A')
                ad_violation = row['rule_advertisement']
                quality = row['rule_overall_quality']
                
                print(f"   Review {idx+1}: '{text}...' (Rating: {rating})")
                print(f"     Advertisement: {'Yes' if ad_violation else 'No'}")
                print(f"     Quality: {'Good' if quality else 'Poor'}")
            
        except FileNotFoundError:
            print("‚ö†Ô∏è Real data not found - using synthetic examples")
            self.demonstrate_synthetic_processing()
    
    def demonstrate_synthetic_processing(self):
        """Fallback demonstration with synthetic data"""
        
        synthetic_reviews = [
            "Great restaurant with amazing food and excellent service!",
            "Visit www.promo.com for 50% off! Call 555-DEALS now!",
            "Average food but my laptop battery died here. Good WiFi.",
            "Never been but heard it's overpriced from my friend."
        ]
        
        for i, review in enumerate(synthetic_reviews):
            print(f"   Synthetic {i+1}: '{review[:40]}...'")
            
            # Quick policy check
            has_url = 'www.' in review or 'http' in review
            has_never = 'never' in review.lower()
            has_tech = any(word in review.lower() for word in ['laptop', 'wifi', 'phone'])
            
            violations = []
            if has_url: violations.append('Advertisement')
            if has_tech: violations.append('Irrelevant')
            if has_never: violations.append('Rant w/o visit')
            
            print(f"     Violations: {violations if violations else 'None'}")
    
    def show_feature_comparison(self):
        """Show the evolution from basic to advanced features"""
        
        print("\nüìà FEATURE ENGINEERING EVOLUTION")
        print("=" * 50)
        
        sample_text = "Amazing restaurant with incredible pasta! The service was outstanding and we'll definitely return."
        
        # Basic features
        basic_features = self.basic_policy.extract_all_features(sample_text)
        
        # Advanced features
        advanced_features = self.advanced_extractor.extract_all_advanced_features(sample_text)
        
        print(f"üìä FEATURE COMPARISON:")
        print(f"   Basic policy features: {len(basic_features)}")
        print(f"   Advanced NLP features: {len(advanced_features)}")
        print(f"   Total enhancement: {len(advanced_features) - len(basic_features)} new features")
        
        print(f"\nüîç FEATURE CATEGORIES:")
        feature_categories = {
            'Linguistic': [k for k in advanced_features.keys() if 'linguistic' in k],
            'Sentiment': [k for k in advanced_features.keys() if 'sentiment' in k],
            'POS Tags': [k for k in advanced_features.keys() if 'pos_' in k],
            'Named Entities': [k for k in advanced_features.keys() if 'ner_' in k],
            'BERT Embeddings': [k for k in advanced_features.keys() if 'bert_' in k],
            'Policy Detection': [k for k in advanced_features.keys() if 'policy_' in k]
        }
        
        for category, features in feature_categories.items():
            if features:
                print(f"   {category}: {len(features)} features")
    
    def run_complete_demo(self):
        """Run the complete NLP engineering demonstration"""
        
        print("üé≠ STARTING COMPLETE NLP ENGINEERING SHOWCASE")
        print("üî¨ Demonstrating advanced capabilities for TikTok Hackathon")
        
        # Run all demonstrations
        self.demonstrate_feature_engineering()
        self.demonstrate_policy_detection()
        self.demonstrate_real_data_processing()
        self.show_feature_comparison()
        
        print("\n" + "=" * 60)
        print("üéâ NLP ENGINEERING SHOWCASE COMPLETE!")
        print("üèÜ ACHIEVEMENTS:")
        print("   ‚úÖ Advanced feature engineering (100+ features)")
        print("   ‚úÖ Sophisticated policy violation detection")
        print("   ‚úÖ Real Google Maps data processing")
        print("   ‚úÖ Multi-layered NLP pipeline")
        print("   ‚úÖ BERT embeddings integration")
        print("   ‚úÖ Linguistic analysis capabilities")
        print("   ‚úÖ Rule-based + ML hybrid approach")
        print("\nüöÄ Ready for ML Engineer handoff!")


if __name__ == "__main__":
    # Run the demonstration
    showcase = NLPShowcase()
    showcase.run_complete_demo()
